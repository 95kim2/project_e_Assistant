{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Input, Activation, Conv2D, Flatten, Dense, MaxPooling2D\n",
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "plt.style.use('dark_background')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43, 34, 26, 1) (43, 1)\n",
      "(11, 34, 26, 1) (11, 1)\n",
      "(44, 34, 26, 1) (44, 1)\n",
      "(11, 34, 26, 1) (11, 1)\n"
     ]
    }
   ],
   "source": [
    "xr_train = np.load('dataset/xr_train.npy').astype(np.float32)\n",
    "yr_train = np.load('dataset/yr_train.npy').astype(np.float32)\n",
    "xr_val = np.load('dataset/xr_val.npy').astype(np.float32)\n",
    "yr_val = np.load('dataset/yr_val.npy').astype(np.float32)\n",
    "xl_train = np.load('dataset/xl_train.npy').astype(np.float32)\n",
    "yl_train = np.load('dataset/yl_train.npy').astype(np.float32)\n",
    "xl_val = np.load('dataset/xl_val.npy').astype(np.float32)\n",
    "yl_val = np.load('dataset/yl_val.npy').astype(np.float32)\n",
    "\n",
    "print(xr_train.shape, yr_train.shape)\n",
    "print(xr_val.shape, yr_val.shape)\n",
    "print(xl_train.shape, yl_train.shape)\n",
    "print(xl_val.shape, yl_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_HEIGHT = 26\n",
    "IMG_WIDTH = 34"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "r_train_generator = train_datagen.flow(\n",
    "    x=xr_train, y=yr_train,\n",
    "    batch_size=32,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "l_train_generator = train_datagen.flow(\n",
    "    x=xl_train, y=yl_train,\n",
    "    batch_size=32,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "r_val_generator = val_datagen.flow(\n",
    "    x=xr_val, y=yr_val,\n",
    "    batch_size=32,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "l_val_generator = val_datagen.flow(\n",
    "    x=xl_val, y=yl_val,\n",
    "    batch_size=32,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 34, 26, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 34, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 17, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 17, 13, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 8, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 8, 6, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 4, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               786944    \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 513       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 880,129\n",
      "Trainable params: 880,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape=(IMG_WIDTH, IMG_HEIGHT, 1))\n",
    "\n",
    "net = Conv2D(32, kernel_size=3, strides=1, padding='same', activation='relu')(inputs)\n",
    "net = MaxPooling2D(pool_size=2)(net)\n",
    "\n",
    "net = Conv2D(64, kernel_size=3, strides=1, padding='same', activation='relu')(net)\n",
    "net = MaxPooling2D(pool_size=2)(net)\n",
    "\n",
    "net = Conv2D(128, kernel_size=3, strides=1, padding='same', activation='relu')(net)\n",
    "net = MaxPooling2D(pool_size=2)(net)\n",
    "\n",
    "net = Flatten()(net)\n",
    "\n",
    "net = Dense(512)(net)\n",
    "net = Activation('relu')(net)\n",
    "net = Dense(1)(net)\n",
    "outputs = Activation('sigmoid')(net)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2/2 [==============================] - 0s 235ms/step - loss: 0.6802 - acc: 0.5349 - val_loss: 0.8476 - val_acc: 0.4545\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.45455, saving model to models/2020_05_22_22_53_22r.h5\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.7693 - acc: 0.5349 - val_loss: 0.7114 - val_acc: 0.4545\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.45455\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.6969 - acc: 0.5349 - val_loss: 0.6925 - val_acc: 0.5455\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.45455 to 0.54545, saving model to models/2020_05_22_22_53_22r.h5\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6954 - acc: 0.4651 - val_loss: 0.6918 - val_acc: 0.5455\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.54545\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6939 - acc: 0.4651 - val_loss: 0.6946 - val_acc: 0.4545\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.54545\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.6921 - acc: 0.5349 - val_loss: 0.6965 - val_acc: 0.4545\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.54545\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6894 - acc: 0.5349 - val_loss: 0.7022 - val_acc: 0.4545\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.54545\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6891 - acc: 0.5349 - val_loss: 0.7070 - val_acc: 0.4545\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.54545\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6949 - acc: 0.5349 - val_loss: 0.7097 - val_acc: 0.4545\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.54545\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6883 - acc: 0.5349 - val_loss: 0.7078 - val_acc: 0.4545\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.54545\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.7004 - acc: 0.5349 - val_loss: 0.7048 - val_acc: 0.4545\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.54545\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6875 - acc: 0.5349 - val_loss: 0.6996 - val_acc: 0.4545\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.54545\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6910 - acc: 0.5349 - val_loss: 0.6964 - val_acc: 0.4545\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.54545\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.6913 - acc: 0.5349 - val_loss: 0.6961 - val_acc: 0.4545\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.54545\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6880 - acc: 0.5349 - val_loss: 0.6958 - val_acc: 0.4545\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.54545\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6870 - acc: 0.5349 - val_loss: 0.6961 - val_acc: 0.4545\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.54545\n",
      "Epoch 17/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6859 - acc: 0.5349 - val_loss: 0.6966 - val_acc: 0.4545\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.54545\n",
      "Epoch 18/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6853 - acc: 0.5349 - val_loss: 0.6981 - val_acc: 0.4545\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.54545\n",
      "Epoch 19/50\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6924 - acc: 0.5349 - val_loss: 0.6994 - val_acc: 0.4545\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.54545\n",
      "Epoch 20/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6900 - acc: 0.5349 - val_loss: 0.6993 - val_acc: 0.4545\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.54545\n",
      "Epoch 21/50\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.6797 - acc: 0.5349 - val_loss: 0.6997 - val_acc: 0.4545\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.54545\n",
      "Epoch 22/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6869 - acc: 0.5349 - val_loss: 0.7009 - val_acc: 0.4545\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.54545\n",
      "Epoch 23/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6927 - acc: 0.5349 - val_loss: 0.7009 - val_acc: 0.4545\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.54545\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "Epoch 24/50\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.6821 - acc: 0.5349 - val_loss: 0.7010 - val_acc: 0.4545\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.54545\n",
      "Epoch 25/50\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.6917 - acc: 0.5349 - val_loss: 0.7011 - val_acc: 0.4545\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.54545\n",
      "Epoch 26/50\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.6921 - acc: 0.5349 - val_loss: 0.7009 - val_acc: 0.4545\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.54545\n",
      "Epoch 27/50\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.6910 - acc: 0.5349 - val_loss: 0.7007 - val_acc: 0.4545\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.54545\n",
      "Epoch 28/50\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.6826 - acc: 0.5349 - val_loss: 0.7005 - val_acc: 0.4545\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.54545\n",
      "Epoch 29/50\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.6846 - acc: 0.5349 - val_loss: 0.7003 - val_acc: 0.4545\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.54545\n",
      "Epoch 30/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6851 - acc: 0.5349 - val_loss: 0.7003 - val_acc: 0.4545\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.54545\n",
      "Epoch 31/50\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.6744 - acc: 0.5349 - val_loss: 0.7003 - val_acc: 0.4545\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.54545\n",
      "Epoch 32/50\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6799 - acc: 0.5349 - val_loss: 0.7006 - val_acc: 0.4545\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.54545\n",
      "Epoch 33/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6826 - acc: 0.5349 - val_loss: 0.7009 - val_acc: 0.4545\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.54545\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "Epoch 34/50\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6747 - acc: 0.5349 - val_loss: 0.7010 - val_acc: 0.4545\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.54545\n",
      "Epoch 35/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.6760 - acc: 0.5349 - val_loss: 0.7012 - val_acc: 0.4545\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.54545\n",
      "Epoch 36/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6939 - acc: 0.5349 - val_loss: 0.7012 - val_acc: 0.4545\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.54545\n",
      "Epoch 37/50\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.6936 - acc: 0.5349 - val_loss: 0.7013 - val_acc: 0.4545\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.54545\n",
      "Epoch 38/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6852 - acc: 0.5349 - val_loss: 0.7013 - val_acc: 0.4545\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.54545\n",
      "Epoch 39/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.6811 - acc: 0.5349 - val_loss: 0.7013 - val_acc: 0.4545\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.54545\n",
      "Epoch 40/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6802 - acc: 0.5349 - val_loss: 0.7014 - val_acc: 0.4545\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.54545\n",
      "Epoch 41/50\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6845 - acc: 0.5349 - val_loss: 0.7014 - val_acc: 0.4545\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.54545\n",
      "Epoch 42/50\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6923 - acc: 0.5349 - val_loss: 0.7015 - val_acc: 0.4545\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.54545\n",
      "Epoch 43/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6847 - acc: 0.5349 - val_loss: 0.7015 - val_acc: 0.4545\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.54545\n",
      "Epoch 44/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6969 - acc: 0.5349 - val_loss: 0.7015 - val_acc: 0.4545\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00044: val_acc did not improve from 0.54545\n",
      "Epoch 45/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.6838 - acc: 0.5349 - val_loss: 0.7014 - val_acc: 0.4545\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.54545\n",
      "Epoch 46/50\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.6855 - acc: 0.5349 - val_loss: 0.7014 - val_acc: 0.4545\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.54545\n",
      "Epoch 47/50\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6876 - acc: 0.5349 - val_loss: 0.7013 - val_acc: 0.4545\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.54545\n",
      "Epoch 48/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6845 - acc: 0.5349 - val_loss: 0.7013 - val_acc: 0.4545\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.54545\n",
      "Epoch 49/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6800 - acc: 0.5349 - val_loss: 0.7012 - val_acc: 0.4545\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.54545\n",
      "Epoch 50/50\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6822 - acc: 0.5349 - val_loss: 0.7012 - val_acc: 0.4545\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.54545\n",
      "Epoch 1/50\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.6690 - acc: 0.5682 - val_loss: 0.7195 - val_acc: 0.3636\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.36364, saving model to models/2020_05_22_22_53_22l.h5\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6746 - acc: 0.5682 - val_loss: 0.7198 - val_acc: 0.3636\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.36364\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6850 - acc: 0.5682 - val_loss: 0.7199 - val_acc: 0.3636\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.36364\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6718 - acc: 0.5682 - val_loss: 0.7202 - val_acc: 0.3636\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.36364\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6785 - acc: 0.5682 - val_loss: 0.7205 - val_acc: 0.3636\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.36364\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6846 - acc: 0.5682 - val_loss: 0.7208 - val_acc: 0.3636\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.36364\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6808 - acc: 0.5682 - val_loss: 0.7210 - val_acc: 0.3636\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.36364\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6772 - acc: 0.5682 - val_loss: 0.7213 - val_acc: 0.3636\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.36364\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6835 - acc: 0.5682 - val_loss: 0.7215 - val_acc: 0.3636\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.36364\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6738 - acc: 0.5682 - val_loss: 0.7218 - val_acc: 0.3636\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.36364\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.6762 - acc: 0.5682 - val_loss: 0.7221 - val_acc: 0.3636\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.36364\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6806 - acc: 0.5682 - val_loss: 0.7224 - val_acc: 0.3636\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.36364\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6812 - acc: 0.5682 - val_loss: 0.7226 - val_acc: 0.3636\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.36364\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6787 - acc: 0.5682 - val_loss: 0.7228 - val_acc: 0.3636\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.36364\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6858 - acc: 0.5682 - val_loss: 0.7231 - val_acc: 0.3636\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.36364\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6782 - acc: 0.5682 - val_loss: 0.7232 - val_acc: 0.3636\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.36364\n",
      "Epoch 17/50\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.6808 - acc: 0.5682 - val_loss: 0.7233 - val_acc: 0.3636\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.36364\n",
      "Epoch 18/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6801 - acc: 0.5682 - val_loss: 0.7235 - val_acc: 0.3636\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.36364\n",
      "Epoch 19/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6770 - acc: 0.5682 - val_loss: 0.7236 - val_acc: 0.3636\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.36364\n",
      "Epoch 20/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6760 - acc: 0.5682 - val_loss: 0.7239 - val_acc: 0.3636\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.36364\n",
      "Epoch 21/50\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6788 - acc: 0.5682 - val_loss: 0.7241 - val_acc: 0.3636\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.36364\n",
      "Epoch 22/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6819 - acc: 0.5682 - val_loss: 0.7243 - val_acc: 0.3636\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.36364\n",
      "Epoch 23/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6786 - acc: 0.5682 - val_loss: 0.7245 - val_acc: 0.3636\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.36364\n",
      "Epoch 24/50\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6863 - acc: 0.5682 - val_loss: 0.7246 - val_acc: 0.3636\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.36364\n",
      "Epoch 25/50\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6670 - acc: 0.5682 - val_loss: 0.7248 - val_acc: 0.3636\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.36364\n",
      "Epoch 26/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6788 - acc: 0.5682 - val_loss: 0.7251 - val_acc: 0.3636\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.36364\n",
      "Epoch 27/50\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.6795 - acc: 0.5682 - val_loss: 0.7253 - val_acc: 0.3636\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.36364\n",
      "Epoch 28/50\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6765 - acc: 0.5682 - val_loss: 0.7255 - val_acc: 0.3636\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.36364\n",
      "Epoch 29/50\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.6787 - acc: 0.5682 - val_loss: 0.7257 - val_acc: 0.3636\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.36364\n",
      "Epoch 30/50\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.6817 - acc: 0.5682 - val_loss: 0.7259 - val_acc: 0.3636\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.36364\n",
      "Epoch 31/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6806 - acc: 0.5682 - val_loss: 0.7260 - val_acc: 0.3636\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.36364\n",
      "Epoch 32/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6783 - acc: 0.5682 - val_loss: 0.7262 - val_acc: 0.3636\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.36364\n",
      "Epoch 33/50\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6886 - acc: 0.5682 - val_loss: 0.7262 - val_acc: 0.3636\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.36364\n",
      "Epoch 34/50\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.6871 - acc: 0.5682 - val_loss: 0.7262 - val_acc: 0.3636\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.36364\n",
      "Epoch 35/50\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.6761 - acc: 0.5682 - val_loss: 0.7262 - val_acc: 0.3636\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.36364\n",
      "Epoch 36/50\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6786 - acc: 0.5682 - val_loss: 0.7262 - val_acc: 0.3636\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.36364\n",
      "Epoch 37/50\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.6691 - acc: 0.5682 - val_loss: 0.7263 - val_acc: 0.3636\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.36364\n",
      "Epoch 38/50\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6797 - acc: 0.5682 - val_loss: 0.7265 - val_acc: 0.3636\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.36364\n",
      "Epoch 39/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6703 - acc: 0.5682 - val_loss: 0.7268 - val_acc: 0.3636\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.36364\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6789 - acc: 0.5682 - val_loss: 0.7271 - val_acc: 0.3636\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.36364\n",
      "Epoch 41/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6884 - acc: 0.5682 - val_loss: 0.7272 - val_acc: 0.3636\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.36364\n",
      "Epoch 42/50\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6697 - acc: 0.5682 - val_loss: 0.7274 - val_acc: 0.3636\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.36364\n",
      "Epoch 43/50\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6653 - acc: 0.5682 - val_loss: 0.7277 - val_acc: 0.3636\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.36364\n",
      "Epoch 44/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6715 - acc: 0.5682 - val_loss: 0.7281 - val_acc: 0.3636\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.36364\n",
      "Epoch 45/50\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6762 - acc: 0.5682 - val_loss: 0.7286 - val_acc: 0.3636\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.36364\n",
      "Epoch 46/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6697 - acc: 0.5682 - val_loss: 0.7291 - val_acc: 0.3636\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.36364\n",
      "Epoch 47/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6739 - acc: 0.5682 - val_loss: 0.7295 - val_acc: 0.3636\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.36364\n",
      "Epoch 48/50\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.6742 - acc: 0.5682 - val_loss: 0.7300 - val_acc: 0.3636\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.36364\n",
      "Epoch 49/50\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6699 - acc: 0.5682 - val_loss: 0.7305 - val_acc: 0.3636\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.36364\n",
      "Epoch 50/50\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6784 - acc: 0.5682 - val_loss: 0.7309 - val_acc: 0.3636\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.36364\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a25e932388>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time = datetime.datetime.now().strftime('%Y_%m_%d_%H_%M_%S')\n",
    "\n",
    "model.fit_generator(\n",
    "    r_train_generator, epochs=50, validation_data=r_val_generator,\n",
    "    callbacks=[\n",
    "        ModelCheckpoint('models/%sr.h5' % (start_time), monitor='val_acc', save_best_only=True, mode='max', verbose=1),\n",
    "        ReduceLROnPlateau(monitor='val_acc', factor=0.2, patience=10, verbose=1, mode='auto', min_lr=1e-05)\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.fit_generator(\n",
    "    l_train_generator, epochs=50, validation_data=l_val_generator,\n",
    "    callbacks=[\n",
    "        ModelCheckpoint('models/%sl.h5' % (start_time), monitor='val_acc', save_best_only=True, mode='max', verbose=1),\n",
    "        ReduceLROnPlateau(monitor='val_acc', factor=0.2, patience=10, verbose=1, mode='auto', min_lr=1e-05)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test acc: 0.5454545454545454\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a2617304c8>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "model = load_model('models/%sr.h5' % (start_time))\n",
    "\n",
    "yr_pred = model.predict(xr_val/255.)\n",
    "yr_pred_logical = (yr_pred > 0.7).astype(np.int)\n",
    "\n",
    "print ('test acc: %s' % accuracy_score(yr_val, yr_pred_logical))\n",
    "cm = confusion_matrix(yr_val, yr_pred_logical)\n",
    "sns.heatmap(cm, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distribution of Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAZwklEQVR4nO3df2yV5f3/8ddpKRFBPdijMk9LS7K6lOngCKfgWALG2B8m0jlJdsCszpEyTZA4NUPdZ+ugy6aOjbgFl3qEoBnQIYgcNlitQ1xHWrzRY1sopad4pj1pQbDFKbBA6/39g3C+lv44h3IOba89H8mdnPu6r/u+r7e2rx6u+9zndkiyBQAwVspwDwAAkFwEPQAYjqAHAMMR9ABgOIIeAAw3ZrgH0J9PPvlEH3300XAPAwBGjaysLN144439bhuRQf/RRx/J6/UO9zAAYNSwLGvAbUzdAIDhCHoAMBxBDwCGI+gBwHAEPQAYjqAHAMPFDPqMjAzt3r1bTU1NOnDggJYtW9ZvvxdeeEGhUEj19fXyeDzR9pKSErW0tKilpUUlJSWJGzkAIG72YMukSZNsj8djS7InTJhgHz582M7Nze3Vp6ioyN65c6ctyZ41a5ZdV1dnS7InTpxoHzlyxJ44caLtdDrtI0eO2E6nc9DzSbIty4rZh4WFhYXl/y+D5WbMd/RHjx5VMBiUJH3xxRc6dOiQ3G53rz7FxcV69dVXJUn79u2T0+nUpEmTVFBQoOrqanV1denkyZOqrq5WYWFhrFMCABLoku6MzcrKksfj0b59+3q1u91utbW1RdcjkYjcbveA7f0pLS3VkiVLJEkul+tShtXL7AXFQ94X+F9St2X7cA8BV0jcF2PHjx+vrVu36rHHHtPnn3/ea5vD4ejT37btAdv74/f75fV65fV6deLEiXiHBQCIIa6gHzNmjLZu3aoNGzZo27ZtfbZHIhFlZmZG1zMyMtTe3j5gOwDgyokr6NeuXatDhw5p9erV/W4PBALRT9TMmjVLn332mY4ePaqqqirl5+fL6XTK6XQqPz9fVVVViRs9ACCmmHP0c+bMUUlJiRoaGqIXZZ955hlNnjxZklRRUaGdO3fqnnvuUWtrq06fPq2HHnpIktTV1aXy8vLot6qtXLlSXV1dyaoFANAPh85//GZEsSxryF9TzMVYID5cjDXLYLnJnbEAYDiCHgAMR9ADgOEIegAwHEEPAIYj6AHAcAQ9ABiOoAcAwxH0AGA4gh4ADEfQA4DhCHoAMBxBDwCGI+gBwHAEPQAYjqAHAMPFDPq1a9fq2LFjamxs7Hf7k08+qWAwqGAwqMbGRnV3d2vixImSpHA4HH0y1YWnTAEArqyYQb9+/XoVFhYOuH3VqlXyeDzyeDx6+umn9c477/R6XOCdd94pj8cz5CdGAQAuT8ygr6mpUWdnZ1wHW7hwoTZt2nTZgwIAJE7C5ujHjRunwsJCbd26Ndpm27befPNN7d+/X6WlpYk6FQDgEoxJ1IHuvfde7d27t9e0zZw5c9TR0aEbbrhB1dXVam5uVk1NTb/7l5aWasmSJZIkl8uVqGEBwP+8hL2j9/l8faZtOjo6JEnHjx/Xtm3blJeXN+D+fr9fXq9XXq9XJ06cSNSwAOB/XkKC/tprr9XcuXO1ffv2aNvVV1+tCRMmRF/n5+frwIEDiTgdAOASxJy62bhxo+bNmyeXy6W2tjaVlZUpLS1NklRRUSFJuu+++/Tmm2/q9OnT0f1uuukmbdu27fxJxozRxo0bVVVVlYwaAACDcEiyh3sQF7Msa8gfx5y9oDjBowHMVLdle+xOGDUGy03ujAUAwxH0AGA4gh4ADEfQA4DhCHoAMBxBDwCGI+gBwHAEPQAYjqAHAMMR9ABgOIIeAAxH0AOA4Qh6ADAcQQ8AhiPoAcBwBD0AGI6gBwDDxQz6tWvX6tixY2psbOx3+9y5c3Xy5EkFg0EFg0H9/Oc/j24rKChQc3OzQqGQli9fnrhRAwDiFjPo169fr8LCwkH71NTUyOPxyOPxqLy8/PyBU1K0Zs0aFRUVaerUqVq4cKFyc3MTM2oAQNxiBn1NTY06Ozsv+cB5eXlqbW1VOBzWuXPnVFlZqeJinucKAFdaQubo77jjDn3wwQfauXOnpk6dKklyu91qa2uL9olEInK73QMeo7S0VJZlybIsuVyuRAwLACBpzOUe4P3331dWVpZOnTqloqIivfHGG7rlllvkcDj69LVte8Dj+P1++f1+SeefZg4ASIzLfkf/+eef69SpU5KkXbt2KS0tTenp6YpEIsrMzIz2y8jIUHt7++WeDgBwiS476G+66aboa6/Xq5SUFH366aeyLEs5OTnKzs5WWlqafD6fAoHA5Z4OAHCJYk7dbNy4UfPmzZPL5VJbW5vKysqUlpYmSaqoqNCCBQv0yCOPqLu7W2fOnJHP55Mk9fT0aOnSpaqqqlJqaqrWrVunpqam5FYDAOjDIWngifNhYlmWvF7vkPadvYBP9gDxqNuyfbiHgAQaLDe5MxYADEfQA4DhCHoAMBxBDwCGI+gBwHAEPQAYjqAHAMMR9ABgOIIeAAxH0AOA4Qh6ADAcQQ8AhiPoAcBwBD0AGI6gBwDDEfQAYDiCHgAMFzPo165dq2PHjqmxsbHf7YsWLVJ9fb3q6+u1d+9efetb34puC4fDamhoUDAYlGVZiRs1ACBuMYN+/fr1KiwsHHB7OBzW3LlzNW3aNJWXl+ull17qtf3OO++Ux+MZ8qMBAQCXJ+bDwWtqapSVlTXg9tra2ujruro6ZWRkJGZkAICESOgc/eLFi7Vr167oum3bevPNN7V//36VlpYOum9paaksy5JlWXK5XIkcFgD8T4v5jj5e8+bN0+LFi/Wd73wn2jZnzhx1dHTohhtuUHV1tZqbm1VTU9Pv/n6/X36/X5KYzweABErIO/rbbrtNL7/8soqLi9XZ2Rlt7+jokCQdP35c27ZtU15eXiJOBwC4BJcd9JmZmXr99df1gx/8QKFQKNp+9dVXa8KECdHX+fn5OnDgwOWeDgBwiWJO3WzcuFHz5s2Ty+VSW1ubysrKlJaWJkmqqKjQL37xC6Wnp+vFF1+UJHV3d8vr9eqmm27Stm3bzp9kzBht3LhRVVVVSSwFANAfhyR7uAdxMcuyhvxxzNkLihM8GsBMdVu2D/cQkECD5SZ3xgKA4Qh6ADAcQQ8AhiPoAcBwBD0AGI6gBwDDEfQAYDiCHgAMR9ADgOEIegAwHEEPAIYj6AHAcAQ9ABiOoAcAwxH0AGA4gh4ADEfQA4Dh4gr6tWvX6tixY2psbBywzwsvvKBQKKT6+np5PJ5oe0lJiVpaWtTS0qKSkpLLHzEA4JLEFfTr169XYWHhgNuLioqUk5OjnJwcLVmyRH/6058kSRMnTlRZWZlmzZqlvLw8lZWVyel0JmbkAIC4xBX0NTU16uzsHHB7cXGxXn31VUnSvn375HQ6NWnSJBUUFKi6ulpdXV06efKkqqurB/2DAQBIvDGJOIjb7VZbW1t0PRKJyO12D9jen9LSUi1ZskSS5HK5EjEsAIOYvaB4uIeAiyTrge0JuRjrcDj6tNm2PWB7f/x+v7xer7xer06cOJGIYQEAlKCgj0QiyszMjK5nZGSovb19wHYAwJWTkKAPBALRT9TMmjVLn332mY4ePaqqqirl5+fL6XTK6XQqPz9fVVVViTglACBOcc3Rb9y4UfPmzZPL5VJbW5vKysqUlpYmSaqoqNDOnTt1zz33qLW1VadPn9ZDDz0kSerq6lJ5ebksy5IkrVy5Ul1dXUkqBQDQH4ek/ifNh5FlWfJ6vUPalwtMAEary7kYO1hucmcsABiOoAcAwxH0AGA4gh4ADEfQA4DhCHoAMBxBDwCGI+gBwHAEPQAYjqAHAMMR9ABgOIIeAAxH0AOA4Qh6ADAcQQ8AhiPoAcBwBD0AGC6uoC8oKFBzc7NCoZCWL1/eZ/vvf/97BYNBBYNBHT58uNfjAru7u6Pbtm8f+tNTAABDE/OZsSkpKVqzZo3uvvtuRSIRWZalQCCgQ4cORfs8/vjj0ddLly6Vx+OJrp85c6bXOgDgyor5jj4vL0+tra0Kh8M6d+6cKisrVVw88HNZFy5cqE2bNiV0kACAoYsZ9G63W21tbdH1SCQit9vdb9/JkydrypQp2r17d7TtqquukmVZqq2tHfQPRGlpqSzLkmVZcrlcl1IDAGAQMaduHA5Hnzbbtvvt6/P5tGXLFn355ZfRtsmTJ6ujoyP6B6CxsVEffvhhn339fr/8fr+k808zBwAkRsx39JFIRJmZmdH1jIwMtbe399vX5/P1mbbp6OiQJIXDYe3Zs4f5egC4wmIGvWVZysnJUXZ2ttLS0uTz+RQIBPr0u+WWWzRx4kTV1tZG25xOp8aOHStJSk9P15w5c9TU1JTA4QMAYok5ddPT06OlS5eqqqpKqampWrdunZqamrRixQrt379fO3bskHT+ImxlZWWvfXNzc1VRUaEvv/xSKSkpevbZZ3t9WgcAkHwOSf1PuA8jy7Lk9XqHtO/sBQNf8AWAkaxuy9DvNRosN7kzFgAMR9ADgOEIegAwHEEPAIYj6AHAcAQ9ABiOoAcAwxH0AGA4gh4ADEfQA4DhCHoAMBxBDwCGI+gBwHAEPQAYjqAHAMMR9ABgOIIeAAwXV9AXFBSoublZoVBIy5cv77P9wQcf1CeffKJgMKhgMKjFixdHt5WUlKilpUUtLS0qKSlJ3MgBAHGJ+czYlJQUrVmzRnfffbcikYgsy1IgEOjz7Ne//OUvevTRR3u1TZw4UWVlZZo5c6Zs29Z7772nQCCgkydPJrYKAMCAYr6jz8vLU2trq8LhsM6dO6fKykoVF8f3XNaCggJVV1erq6tLJ0+eVHV1tQoLCy970ACA+MUMerfbrba2tuh6JBKR2+3u0+/+++9XfX29XnvtNWVkZFzSvpJUWloqy7JkWZZcLtclFwIA6F/MoHc4HH3abNvutb5jxw5lZ2dr2rRpeuutt/TKK6/Eve8Ffr9fXq9XXq9XJ06ciGvwAIDYYgZ9JBJRZmZmdD0jI0Pt7e29+nR2durs2bOSzgf2jBkz4t4XAJBcMYPesizl5OQoOztbaWlp8vl8CgQCvfpMmjQp+nr+/PnRC7VVVVXKz8+X0+mU0+lUfn6+qqqqElwCAGAwMT9109PTo6VLl6qqqkqpqalat26dmpqatGLFCu3fv187duzQsmXLNH/+fHV3d6uzs1M//OEPJUldXV0qLy+XZVmSpJUrV6qrqyupBQEAenNI6n/SfBhZliWv1zukfWcviO8TQQAw0tRt2T7kfQfLTe6MBQDDEfQAYDiCHgAMR9ADgOEIegAwHEEPAIYj6AHAcAQ9ABiOoAcAwxH0AGA4gh4ADEfQA4DhCHoAMBxBDwCGI+gBwHAEPQAYjqAHAMPFFfQFBQVqbm5WKBTS8uXL+2z/yU9+ooMHD6q+vl5vvfWWJk+eHN3W3d2tYDCoYDCo7duH/vQUAMDQxHxmbEpKitasWaO7775bkUhElmUpEAhEHwAuScFgUDNnztSZM2f08MMP6/nnn5fP55MknTlzRh6PJ3kVAAAGFfMdfV5enlpbWxUOh3Xu3DlVVlaquLj3c1n37NmjM2fOSJLq6uqUkZGRnNECAC5ZzKB3u91qa2uLrkciEbnd7gH7L168WLt27YquX3XVVbIsS7W1tX3+QHxVaWmpLMuSZVlyuVzxjh8AEEPMqRuHw9Gnzbbtfvs+8MADmjlzpubOnRttmzx5sjo6OjRlyhTt3r1bjY2N+vDDD/vs6/f75ff7JZ1/mjkAIDFivqOPRCLKzMyMrmdkZKi9vb1Pv7vuuks/+9nPNH/+fJ09ezba3tHRIUkKh8Pas2cP8/UAcIXFDHrLspSTk6Ps7GylpaXJ5/MpEAj06jN9+nRVVFRo/vz5On78eLTd6XRq7NixkqT09HTNmTNHTU1NCS4BADCYmFM3PT09Wrp0qaqqqpSamqp169apqalJK1as0P79+7Vjxw799re/1YQJE/Taa69Jkj7++GMVFxcrNzdXFRUV+vLLL5WSkqJnn32216d1AADJ55DU/4T7MLIsS16vd0j7zl4w8AVfABjJ6rYM/V6jwXKTO2MBwHAEPQAYjqAHAMMR9ABgOIIeAAxH0AOA4Qh6ADAcQQ8AhiPoAcBwBD0AGI6gBwDDEfQAYDiCHgAMR9ADgOEIegAwHEEPAIYj6AHAcHEFfUFBgZqbmxUKhbR8+fI+28eOHavKykqFQiHV1dUpKysruu2pp55SKBRSc3Oz8vPzEzdyAEBcYgZ9SkqK1qxZo6KiIk2dOlULFy5Ubm5urz6LFy9WV1eXcnJytHr1aj333HOSpNzcXPl8Pn3zm99UYWGhXnzxRaWk8I8IALiSYqZuXl6eWltbFQ6Hde7cOVVWVqq4uPdzWYuLi/XKK69IkrZs2aK77ror2l5ZWamzZ8/q3//+t1pbW5WXl5eEMgAAAxkTq4Pb7VZbW1t0PRKJaNasWQP26enp0Weffab09HS53W7V1dX12tftdvd7ntLSUi1ZskSS9I1vfEOWZfXbz+Vy6cSJE7GGPaJRw8hADSMDNXzF8v8b8q5fnTK/WMygdzgcfdps246rTzz7XuD3++X3+2MNZ9AnnY8W1DAyUMPIQA3JF3PqJhKJKDMzM7qekZGh9vb2AfukpqbquuuuU2dnZ1z7AgCSK2bQW5alnJwcZWdnKy0tTT6fT4FAoFefQCCgBx98UJK0YMEC7d69O9ru8/k0duxYZWdnKycnR++++24SygAADCRV0i8H62DbtkKhkDZs2KBHH31Uf/7zn/X6669rxYoVuuaaa9TS0qKGhgY98MAD+vWvf63p06fr4Ycf1smTJ3X8+HFdf/31evnll7Vo0SItW7ZMoVDosgf9/vvvX/Yxhhs1jAzUMDJQQ3I5JPU/aQ4AMAIfagcAwxH0AGC4YQ/6WF+vcMH9998v27Y1Y8YMSdKiRYsUDAajS09Pj6ZNmyZJuv3229XQ0KBQKKQXXnhh1NUwbtw4/fWvf9WhQ4d04MAB/eY3vxl1NXzV9u3b1djYmNTxS8mpIS0tTRUVFTp8+LAOHTqk733ve6OuBp/Pp4aGBtXX12vXrl1KT08fkTWMGTNG69evV0NDg5qamvTUU09d8jFHag0ZGRnavXu3mpqadODAAS1btizpNVzMHq4lJSXFbm1ttadMmWKnpaXZH3zwgZ2bm9un34QJE+x33nnHrq2ttWfMmNFn+6233mofOXIkur5v3z579uzZtiR7586ddmFh4aiqYdy4cfa8efNsSXZaWpr9z3/+c9TVcGG577777A0bNtiNjY2j8mfpl7/8pV1eXm5Lsh0Oh52enj6qakhNTbWPHTsWHfdzzz1nl5WVjcgaFi5caG/atCn6OxAOh+2srKy4jzmSa5g0aZLt8Xii+x0+fDipNfSpScMonq9XkKTy8nI9//zz+u9//9vvcRYuXKhNmzZJkiZNmqRrr702ekfuq6++qu9+97ujqoYzZ85oz549kqRz587p/fffV0ZGxqiqQZLGjx+vxx9/XL/61a+SNvYLklXDj370o+i/qGzb1qeffpqcApScGhwOhxwOh8aPHy9Juvbaa5N6L8vl1GDbtsaPH6/U1FSNGzdOZ8+e1X/+85+4jzmSazh69KiCwaAk6YsvvtChQ4cG/JaAZBjWoO/v6xUuLn769OnKzMzU3/72twGP8/3vfz/6g+12uxWJRAY9ZiIlo4avuu6663TvvffqH//4R+IGfZFk1VBeXq7f/e53On36dOIHfZFk1HDddddJOl/He++9p82bN+vGG29MwujPS0YN3d3deuSRR9TY2Kj29nZNnTpVa9euTU4BurwatmzZolOnTqmjo0Mff/yxVq1apa6urriOOdJr+KqsrCx5PB7t27cvaTVcbFiDPtZXJDgcDq1evVpPPPHEgMfIy8vT6dOndfDgwbiOmWjJqOGC1NRUbdq0SX/4wx8UDocTN+iLJKOGadOm6etf/7reeOONxA+4H8moYcyYMcrMzNTevXs1Y8YM1dbWatWqVYkf/FfGeLFE1PDII4/I4/Ho5ptvVkNDg55++unED/4rY7xYvDXk5eWpp6dHN998s6ZMmaInnnhCU6ZMGVW/0wPVcMH48eO1detWPfbYY/r888+TU0A/hjXoY31FwjXXXKNbb71Ve/bsUTgc1uzZsxUIBKIXPqTzF5q++i4yEon0muZI9tcuJKOGC1566aUrckE5GTXccccdmjFjhsLhsP71r3/plltu0dtvvz2qavj000916tQpbdu2TZL02muv6fbbbx9VNUyfPl2S9OGHH0qSNm/erG9/+9sjsoZFixbp73//u7q7u3X8+HHt3btXM2fOvOJfpZKMGqTzf3S3bt2qDRs2RH+mrqQrdkHg4iU1NdU+cuSInZ2dHb3oMXXq1AH7v/32270uPjkcDrutrc2eMmVKr37vvvuuPWvWLFs6fzG2qKho1NVQXl5ub9myxXY4HKP2/8OFJSsrK+kXY5NVw6ZNm+w777zTlmQ/+OCD9ubNm0dVDV/72tfs9vZ22+Vy2ZLslStX2qtWrRqRNfz0pz+1161bZ0uyr776avvgwYP2bbfddsnHHIk1SLJfeeUVe/Xq1Ukbd4xlWE4aXYqKiuzDhw/bra2t9jPPPGNLslesWGHfe++9g/4HlWTPnTvXrq2t7dNvxowZdmNjo93a2mr/8Y9/HHU1uN1u27Ztu6mpyQ4Gg3YwGLQXL148qmr46nIlgj5ZNUyePNl+55137Pr6evutt96yMzMzR10NP/7xj+2mpia7vr7eDgQC9vXXXz8iaxg/fry9efNm+8CBA/bBgwftJ598ctBjjqYa5syZY9u2bdfX10d/p5P5BvTiha9AAADDDfsNUwCA5CLoAcBwBD0AGI6gBwDDEfQAYDiCHgAMR9ADgOH+H13gWEFotcAoAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.distplot(yr_pred, kde=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
